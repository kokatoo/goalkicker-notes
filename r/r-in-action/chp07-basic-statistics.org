#+STARTUP: showeverything
#+title: R in Action

* Chapter 7: Basic statistics

** Section 7.1 Descriptive statistics

#+begin_src R
  myvars <- c("mpg", "hp", "wt")

  > summary(mtcars[myvars])
         mpg              hp              wt       
  Min.   :10.40   Min.   : 52.0   Min.   :1.513  
  1st Qu.:15.43   1st Qu.: 96.5   1st Qu.:2.581  
  Median :19.20   Median :123.0   Median :3.325  
  Mean   :20.09   Mean   :146.7   Mean   :3.217  
  3rd Qu.:22.80   3rd Qu.:180.0   3rd Qu.:3.610  
  Max.   :33.90   Max.   :335.0   Max.   :5.424
#+end_src

#+begin_src R
  mystats <- function(x, na.omit=FALSE) {
    if (na.omit) {
      x <- x[!is.na(x)]
    }

    m <- mean(x)
    n <- length(x)
    s <- sd(x)
    skew <- sum((x-m)^3/s^3)/n
    kurt <- sum((x-m)^4/s^4)/n - 3

    return(c(n=n, mean=m, stdev=s, skew=skew, kurtosis=kurt))
  }

  myvars <- c("mpg", "hp", "wt")

  > sapply(mtcars[myvars], mystats)
                 mpg          hp          wt
  n        32.000000  32.0000000 32.00000000
  mean     20.090625 146.6875000  3.21725000
  stdev     6.026948  68.5628685  0.97845744
  skew      0.610655   0.7260237  0.42314646
  kurtosis -0.372766  -0.1355511 -0.02271075
#+end_src

#+begin_src R
  library(Hmisc)

  myvars <- c("mpg", "hp", "wt")
  describe(mtcars[myvars])

   3  Variables      32  Observations
  --------------------------------------------------------------------------------
  mpg 
         n  missing distinct     Info     Mean      Gmd      .05      .10 
        32        0       25    0.999    20.09    6.796    12.00    14.34 
       .25      .50      .75      .90      .95 
     15.43    19.20    22.80    30.09    31.30 

  lowest : 10.4 13.3 14.3 14.7 15.0, highest: 26.0 27.3 30.4 32.4 33.9
  --------------------------------------------------------------------------------
  hp 
         n  missing distinct     Info     Mean      Gmd      .05      .10 
        32        0       22    0.997    146.7    77.04    63.65    66.00 
       .25      .50      .75      .90      .95 
     96.50   123.00   180.00   243.50   253.55 

  lowest :  52  62  65  66  91, highest: 215 230 245 264 335
  --------------------------------------------------------------------------------
  wt 
         n  missing distinct     Info     Mean      Gmd      .05      .10 
        32        0       29    0.999    3.217    1.089    1.736    1.956 
       .25      .50      .75      .90      .95 
     2.581    3.325    3.610    4.048    5.293 

  lowest : 1.513 1.615 1.835 1.935 2.140, highest: 3.845 4.070 5.250 5.345 5.424
  --------------------------------------------------------------------------------
#+end_src

#+begin_src R
  library(pastecs)

  myvars <- c("mpg", "hp", "wt")

  > stat.desc(mtcars[myvars])
                       mpg           hp          wt
  nbr.val       32.0000000   32.0000000  32.0000000
  nbr.null       0.0000000    0.0000000   0.0000000
  nbr.na         0.0000000    0.0000000   0.0000000
  min           10.4000000   52.0000000   1.5130000
  max           33.9000000  335.0000000   5.4240000
  range         23.5000000  283.0000000   3.9110000
  sum          642.9000000 4694.0000000 102.9520000
  median        19.2000000  123.0000000   3.3250000
  mean          20.0906250  146.6875000   3.2172500
  SE.mean        1.0654240   12.1203173   0.1729685
  CI.mean.0.95   2.1729465   24.7195501   0.3527715
  var           36.3241028 4700.8669355   0.9573790
  std.dev        6.0269481   68.5628685   0.9784574
  coef.var       0.2999881    0.4674077   0.3041285
#+end_src

#+begin_src R
  library(psych)

  myvars <- c("mpg", "hp", "wt")
  > describe(mtcars[myvars])

      vars  n   mean    sd median trimmed   mad   min    max  range skew kurtosis
  mpg    1 32  20.09  6.03  19.20   19.70  5.41 10.40  33.90  23.50 0.61    -0.37
  hp     2 32 146.69 68.56 123.00  141.19 77.10 52.00 335.00 283.00 0.73    -0.14
  wt     3 32   3.22  0.98   3.33    3.15  0.77  1.51   5.42   3.91 0.42    -0.02
         se
  mpg  1.07
  hp  12.12
  wt   0.17
#+end_src

*** 7.1.3 Descriptive statistics by group

#+begin_src R
  myvars <- c("mpg", "hp", "wt") 
  > aggregate(mtcars[myvars], by=list(am=mtcars$am), mean)
    am      mpg       hp       wt
  1  0 17.14737 160.2632 3.768895
  2  1 24.39231 126.8462 2.411000

  > aggregate(mtcars[myvars], by=list(am=mtcars$am), sd)
    am      mpg       hp        wt
  1  0 3.833966 53.90820 0.7774001
  2  1 6.166504 84.06232 0.6169816
#+end_src

#+begin_src R
  dstats <- function(x) sapply(x, mystats)

  myvars <- c("mpg", "hp", "wt")
  > by(mtcars[myvars], mtcars$am, dstats)
  mtcars$am: 0
                   mpg           hp         wt
  n        19.00000000  19.00000000 19.0000000
  mean     17.14736842 160.26315789  3.7688947
  stdev     3.83396639  53.90819573  0.7774001
  skew      0.01395038  -0.01422519  0.9759294
  kurtosis -0.80317826  -1.20969733  0.1415676
  ------------------------------------------------------------ 
  mtcars$am: 1
                   mpg          hp         wt
  n        13.00000000  13.0000000 13.0000000
  mean     24.39230769 126.8461538  2.4110000
  stdev     6.16650381  84.0623243  0.6169816
  skew      0.05256118   1.3598859  0.2103128
  kurtosis -1.45535200   0.5634635 -1.1737358
#+end_src

*** 7.1.4 Additional methods by group

#+begin_src R
  library(doBy)

  > summaryBy(mpg + hp + wt ~ am, data=mtcars, FUN=mystats)
    am mpg.n mpg.mean mpg.stdev   mpg.skew mpg.kurtosis hp.n  hp.mean hp.stdev
  1  0    19 17.14737  3.833966 0.01395038   -0.8031783   19 160.2632 53.90820
  2  1    13 24.39231  6.166504 0.05256118   -1.4553520   13 126.8462 84.06232
        hp.skew hp.kurtosis wt.n  wt.mean  wt.stdev   wt.skew wt.kurtosis
  1 -0.01422519  -1.2096973   19 3.768895 0.7774001 0.9759294   0.1415676
  2  1.35988586   0.5634635   13 2.411000 0.6169816 0.2103128  -1.1737358
#+end_src

#+begin_src R
  library(psych)

  myvars <- c("mpg", "hp", "wt")
  
  > describeBy(mtcars[myvars], list(am=mtcars$am))
  Descriptive statistics by group 
  am: 0
      vars  n   mean    sd median trimmed   mad   min    max  range  skew
  mpg    1 19  17.15  3.83  17.30   17.12  3.11 10.40  24.40  14.00  0.01
  hp     2 19 160.26 53.91 175.00  161.06 77.10 62.00 245.00 183.00 -0.01
  wt     3 19   3.77  0.78   3.52    3.75  0.45  2.46   5.42   2.96  0.98
      kurtosis    se
  mpg    -0.80  0.88
  hp     -1.21 12.37
  wt      0.14  0.18
  ------------------------------------------------------------ 
  am: 1
      vars  n   mean    sd median trimmed   mad   min    max  range skew kurtosis
  mpg    1 13  24.39  6.17  22.80   24.38  6.67 15.00  33.90  18.90 0.05    -1.46
  hp     2 13 126.85 84.06 109.00  114.73 63.75 52.00 335.00 283.00 1.36     0.56
  wt     3 13   2.41  0.62   2.32    2.39  0.68  1.51   3.57   2.06 0.21    -1.17
         se
  mpg  1.71
  hp  23.31
  wt   0.17
#+end_src

*** 7.1.5 Visualizing results

    For quantitative variables, you can use histograms, density plots, box plots
    and dot plots.

** Section 7.2 Frequency and contingency tables

*** 7.2.1 Generating frequency tables

| Function                       | Parameter                                                                         |
|--------------------------------+-----------------------------------------------------------------------------------|
| ~table(var1,..., varN)~        | Creates an N-way contingency table from N categorical factors                     |
| ~xtabs(formula, data)~         | Creates an N-way contingency table based on a formula and a matrix or data frame  |
| ~prop.table(table, margins)~   | Expresses table entries as fractions of the marginal table defined by the margins |
| ~margin.table(table, margins)~ | Computes the sum of table entries for a marginal table defined by the margins     |
| ~addmargins(table, margins)~   | Puts summary margins (sums by default) on a table                                 |
| ~ftable(table)~                | Creates a compact, “flat” contingency table                                       |

**** One-Way Tables

#+begin_src R
  library(vcd)

  mytable <- with(Arthritis, table(Improved))

  > mytable
  Improved
    None   Some Marked 
      42     14     28 

  > prop.table(mytable)*100
  Improved
      None     Some   Marked 
  50.00000 16.66667 33.33333
#+end_src

**** Two-Way Tables

#+begin_src R
  mytable <- with(Arthritis, table(Treatment, Improved))

  mytable <- xtabs(~ Treatment+Improved, data=Arthritis)

  > mytable
           Improved
  Treatment None Some Marked
    Placebo   29    7      7
    Treated   13    7     21

  # row sums (Treatment)
  > margin.table(mytable, 1)
  Treatment
    Placebo Treated 
         43      41 

  # row proportions (Treatment)
  > prop.table(mytable, 1)
           Improved
  Treatment      None      Some    Marked
    Placebo 0.6744186 0.1627907 0.1627907
    Treated 0.3170732 0.1707317 0.5121951

  # column sums (Improved)
  > margin.table(mytable, 2)
  Improved
    None   Some Marked 
      42     14     28 

  # column proportions (Improved)
  > prop.table(mytable, 2)
           Improved
  Treatment      None      Some    Marked
    Placebo 0.6904762 0.5000000 0.2500000
    Treated 0.3095238 0.5000000 0.7500000
#+end_src

#+begin_src R
  # cell proportions
  > prop.table(mytable)
             Improved
  Treatment       None       Some     Marked
    Placebo 0.34523810 0.08333333 0.08333333
    Treated 0.15476190 0.08333333 0.25000000

  > addmargins(mytable)
           Improved
  Treatment None Some Marked Sum
    Placebo   29    7      7  43
    Treated   13    7     21  41
    Sum       42   14     28  84

  > addmargins(prop.table(mytable))
           Improved
  Treatment       None       Some     Marked        Sum
    Placebo 0.34523810 0.08333333 0.08333333 0.51190476
    Treated 0.15476190 0.08333333 0.25000000 0.48809524
    Sum     0.50000000 0.16666667 0.33333333 1.00000000

  # add sum row
  > addmargins(prop.table(mytable, 1), 2)
           Improved
  Treatment      None      Some    Marked       Sum
    Placebo 0.6744186 0.1627907 0.1627907 1.0000000
    Treated 0.3170732 0.1707317 0.5121951 1.0000000

  # add sum column
  > addmargins(prop.table(mytable, 2), 1)
           Improved
  Treatment      None      Some    Marked
    Placebo 0.6904762 0.5000000 0.2500000
    Treated 0.3095238 0.5000000 0.7500000
    Sum     1.0000000 1.0000000 1.0000000
#+end_src

**** Two-way table using ~CrossTable~

#+begin_src R
  library(gmodels)

  CrossTable(Arthritis$Treatment, Arthritis$Improved)
  >  
     Cell Contents
  |-------------------------|
  |                       N |
  | Chi-square contribution |
  |           N / Row Total |
  |           N / Col Total |
  |         N / Table Total |
  |-------------------------|

 
  Total Observations in Table:  84 

 
                      | Arthritis$Improved 
  Arthritis$Treatment |      None |      Some |    Marked | Row Total | 
  --------------------|-----------|-----------|-----------|-----------|
              Placebo |        29 |         7 |         7 |        43 | 
                      |     2.616 |     0.004 |     3.752 |           | 
                      |     0.674 |     0.163 |     0.163 |     0.512 | 
                      |     0.690 |     0.500 |     0.250 |           | 
                      |     0.345 |     0.083 |     0.083 |           | 
  --------------------|-----------|-----------|-----------|-----------|
              Treated |        13 |         7 |        21 |        41 | 
                      |     2.744 |     0.004 |     3.935 |           | 
                      |     0.317 |     0.171 |     0.512 |     0.488 | 
                      |     0.310 |     0.500 |     0.750 |           | 
                      |     0.155 |     0.083 |     0.250 |           | 
  --------------------|-----------|-----------|-----------|-----------|
         Column Total |        42 |        14 |        28 |        84 | 
                      |     0.500 |     0.167 |     0.333 |           | 
  --------------------|-----------|-----------|-----------|-----------|
#+end_src

**** Multidimensional Tables

#+begin_src R
  # 3-way contingency table
  mytable <- xtabs(~ Treatment+Sex+Improved, data=Arthritis)

  > mytable
  , , Improved = None

           Sex
  Treatment Female Male
    Placebo     19   10
    Treated      6    7

  , , Improved = Some

           Sex
  Treatment Female Male
    Placebo      7    0
    Treated      5    2

  , , Improved = Marked

           Sex
  Treatment Female Male
    Placebo      6    1
    Treated     16    5

  # better formatting
  > ftable(mytable)
                   Improved None Some Marked
  Treatment Sex                             
  Placebo   Female            19    7      6
            Male              10    0      1
  Treated   Female             6    5     16
            Male               7    2      5

  > margin.table(mytable, 1)
  Treatment
  Placebo Treated 
       43      41 

  > margin.table(mytable, 2)
  Sex
  Female   Male 
      59     25

  > margin.table(mytable, 3)
  Improved
    None   Some Marked 
      42     14     28 

  # Treatment x Improved marginal freqs
  > margin.table(mytable, c(1, 3))
           Improved
  Treatment None Some Marked
    Placebo   29    7      7
    Treated   13    7     21

  # Improved proportions for Treat x Sex
  > ftable(prop.table(mytable, c(1, 2)))
                   Improved       None       Some     Marked
  Treatment Sex                                             
  Placebo   Female          0.59375000 0.21875000 0.18750000
            Male            0.90909091 0.00000000 0.09090909
  Treated   Female          0.22222222 0.18518519 0.59259259
            Male            0.50000000 0.14285714 0.35714286

  > ftable(addmargins(prop.table(mytable, c(1, 2)), 3))

                   Improved       None       Some     Marked        Sum
  Treatment Sex                                                        
  Placebo   Female          0.59375000 0.21875000 0.18750000 1.00000000
            Male            0.90909091 0.00000000 0.09090909 1.00000000
  Treated   Female          0.22222222 0.18518519 0.59259259 1.00000000
            Male            0.50000000 0.14285714 0.35714286 1.00000000
#+end_src

*** 7.2.2 Tests of independence

**** Chi-square test of independence

     Use ~chisq.test()~ to test the independence of row and column variables.
     The p-values are the probability of obtaining the sample results assuming
     independence of the row and column varaibles in the population.

#+begin_src R
  library(vcd)

  mytable <- xtabs( ~ Treatment+Improved, data=Arthritis)

  > chisq.test(mytable)
    Pearson's Chi-squared test

  data:  mytable
  X-squared = 13.055, df = 2, p-value = 0.001463

  mytable <- xtabs(~Improved+Sex, data=Arthritis)

  > chisq.test(mytable)
    Pearson's Chi-squared test

  data:  mytable
  X-squared = 4.8407, df = 2, p-value = 0.08889

  Warning message:
  In chisq.test(mytable) : Chi-squared approximation may be incorrect
#+end_src

**** Fisher's exact test

     Evaluates the null hypothesis of independence of rows and columns in a
     contingency table with fixed marginals.

#+begin_src R
  mytable <- xtabs( ~ Treatment+Improved, data=Arthritis)

  > fisher.test(mytable)
    Fisher's Exact Test for Count Data

  data:  mytable
  p-value = 0.001393
  alternative hypothesis: two.sided
#+end_src

**** Cochran–Mantel–Haenszel test

     The ~mantelhaen.test()~ function provides a Cochran–Mantel–Haenszel
     chi-square test of the null hypothesis that two nominal variables are
     conditionally independent in each stratum of a third variable. The
     following code tests the hypothesis that the Treatment and Improved
     variables are independent within each level for Sex. i.e. there are no
     3-way interaction.

#+begin_src R
  mytable <- xtabs( ~ Treatment+Improved+Sex, data=Arthritis)

  > mantelhaen.test(mytable)
    Cochran-Mantel-Haenszel test

  data:  mytable
  Cochran-Mantel-Haenszel M^2 = 14.632, df = 2, p-value = 0.0006647
#+end_src

*** 7.2.3 Measures of association

**** Measures of association for a two-way table

     After testing for independence, you want to access the magnitude of
     association. Large values indicate stronger associations.

#+begin_src R
  library(vcd)

  mytable <- xtabs( ~ Treatment+Improved, data=Arthritis)

  > assocstats(mytable)
                      X^2 df  P(> X^2)
  Likelihood Ratio 13.530  2 0.0011536
  Pearson          13.055  2 0.0014626

  Phi-Coefficient   : NA 
  Contingency Coeff.: 0.367 
  Cramer's V        : 0.394 
#+end_src

*** 7.2.4 Visualizing results

    You can typically use bar charts to visalize frequencies in 1 direction. Or
    use ~vcd~ package mosaic and association plots for visualizing relationships
    among categorical variables in multidimensional datasets

** Section 7.3 Correlations
   
*** 7.3.1 Types of correlations

   R can produce a variety of correlation coefficients, including Pearson,
   Spearman, Kendall, partial, polychoric, and polyserial.

#+begin_src R
  cor(x, use="everything", method="pearson")
#+end_src
| Option   | Description                                                                                                                                                                                                       |
|----------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| ~x~      | Matrix or data frame.                                                                                                                                                                                             |
| ~use~    | Specifies the handling of missing data. ~all.obs~ (assumes no missing data), everything (missing values will be set to missing), complete.obs (listwise deletion), and pairwise.complete.obs (pairwise deletion). |
| ~method~ | Options are pearson, spearman, and kendall.                                                                                                                                                                       |

#+begin_src R
  states<- state.x77[,1:6]

  > cov(states)
                Population      Income   Illiteracy     Life Exp      Murder
  Population 19931683.7588 571229.7796  292.8679592 -407.8424612 5663.523714
  Income       571229.7796 377573.3061 -163.7020408  280.6631837 -521.894286
  Illiteracy      292.8680   -163.7020    0.3715306   -0.4815122    1.581776
  Life Exp       -407.8425    280.6632   -0.4815122    1.8020204   -3.869480
  Murder         5663.5237   -521.8943    1.5817755   -3.8694804   13.627465
  HS Grad       -3551.5096   3076.7690   -3.2354694    6.3126849  -14.549616
                  HS Grad
  Population -3551.509551
  Income      3076.768980
  Illiteracy    -3.235469
  Life Exp       6.312685
  Murder       -14.549616
  HS Grad       65.237894

  > cor(states)
              Population     Income Illiteracy    Life Exp     Murder     HS Grad
  Population  1.00000000  0.2082276  0.1076224 -0.06805195  0.3436428 -0.09848975
  Income      0.20822756  1.0000000 -0.4370752  0.34025534 -0.2300776  0.61993232
  Illiteracy  0.10762237 -0.4370752  1.0000000 -0.58847793  0.7029752 -0.65718861
  Life Exp   -0.06805195  0.3402553 -0.5884779  1.00000000 -0.7808458  0.58221620
  Murder      0.34364275 -0.2300776  0.7029752 -0.78084575  1.0000000 -0.48797102
  HS Grad    -0.09848975  0.6199323 -0.6571886  0.58221620 -0.4879710  1.00000000

  > cor(states, method="spearman")
             Population     Income Illiteracy   Life Exp     Murder    HS Grad
  Population  1.0000000  0.1246098  0.3130496 -0.1040171  0.3457401 -0.3833649
  Income      0.1246098  1.0000000 -0.3145948  0.3241050 -0.2174623  0.5104809
  Illiteracy  0.3130496 -0.3145948  1.0000000 -0.5553735  0.6723592 -0.6545396
  Life Exp   -0.1040171  0.3241050 -0.5553735  1.0000000 -0.7802406  0.5239410
  Murder      0.3457401 -0.2174623  0.6723592 -0.7802406  1.0000000 -0.4367330
  HS Grad    -0.3833649  0.5104809 -0.6545396  0.5239410 -0.4367330  1.0000000

  # only show varibles you are interested in
  x <- states[, c("Population", "Income", "Illiteracy", "HS Grad")]
  y <- states[, c("Life Exp", "Murder")]
  > cor(x,y)
                Life Exp     Murder
  Population -0.06805195  0.3436428
  Income      0.34025534 -0.2300776
  Illiteracy -0.58847793  0.7029752
  HS Grad     0.58221620 -0.4879710

#+end_src

**** Partial correlations

     A partial correlation is a correlation between two quantitative variables,
     controlling for one or more other quantitative variables.

#+begin_src R
  library(ggm)

  colnames(states)

  # correlation between variable 1 and 5 controlling for 2, 3, and 6
  > pcor(c(1, 5, 2, 3, 6), cov(states))
  [1] 0.3462724
#+end_src

*** 7.3.2 Testing correlations for significance

    The typical null hypothesis is no relationship.

    Where x and y are the variables to be correlated, alternative specifies a
    two-tailed or one-tailed test (~two.side~, ~less~, or ~greater~), and method
    specifies the type of correlation (~pearson~, ~kendall~, or ~spearman~) to
    compute.

#+begin_src R
  cor.test(x, y, alternative=, method=)
#+end_src

#+begin_src R
  > cor.test(states[,3], states[,5])

    Pearson's product-moment correlation

  data:  states[, 3] and states[, 5]
  t = 6.8479, df = 48, p-value = 1.258e-08
  alternative hypothesis: true correlation is not equal to 0
  95 percent confidence interval:
   0.5279280 0.8207295
  sample estimates:
        cor 
  0.7029752 
#+end_src

#+begin_src R
  library(psych)

  > corr.test(states, use="complete")

  Call:corr.test(x = states, use = "complete")
  Correlation matrix 
             Population Income Illiteracy Life Exp Murder HS Grad
  Population       1.00   0.21       0.11    -0.07   0.34   -0.10
  Income           0.21   1.00      -0.44     0.34  -0.23    0.62
  Illiteracy       0.11  -0.44       1.00    -0.59   0.70   -0.66
  Life Exp        -0.07   0.34      -0.59     1.00  -0.78    0.58
  Murder           0.34  -0.23       0.70    -0.78   1.00   -0.49
  HS Grad         -0.10   0.62      -0.66     0.58  -0.49    1.00
  Sample Size 
  [1] 50
  Probability values (Entries above the diagonal are adjusted for multiple tests.) 
             Population Income Illiteracy Life Exp Murder HS Grad
  Population       0.00   0.59       1.00      1.0   0.10       1
  Income           0.15   0.00       0.01      0.1   0.54       0
  Illiteracy       0.46   0.00       0.00      0.0   0.00       0
  Life Exp         0.64   0.02       0.00      0.0   0.00       0
  Murder           0.01   0.11       0.00      0.0   0.00       0
  HS Grad          0.50   0.00       0.00      0.0   0.00       0

   To see confidence intervals of the correlations, print with the short=FALSE option
#+end_src

*** 7.3.3 Visualizing correlations

    Bivariate relationships underlying correlation can be visualized through
    scatter plots and scatter plot matrices. Correlograms provide a way for
    comparing a large number of correlation coefficients.

** Section 7.4 T-tests

   Here we focus on group comparsion where the outcme varible is continous and
   assumed to be normally distributed. Check section 7.3 for outcome that is categorical.

*** 7.4.1 Independent t-test

#+begin_src R
  library(MASS)

  > t.test(Prob ~ So, data=UScrime)

    Welch Two Sample t-test

  data:  Prob by So
  t = -3.8954, df = 24.925, p-value = 0.0006506
  alternative hypothesis: true difference in means is not equal to 0
  95 percent confidence interval:
   -0.03852569 -0.01187439
  sample estimates:
  mean in group 0 mean in group 1 
       0.03851265      0.06371269 
#+end_src

*** 7.4.2 Dependent t-test

#+begin_src R
  library(MASS)

  > sapply(UScrime[c("U1","U2")], function(x)(c(mean=mean(x),sd=sd(x))))
             U1       U2
  mean 95.46809 33.97872
  sd   18.02878  8.44545

  > with(UScrime, t.test(U1, U2, paired=TRUE))

    Paired t-test

  data:  U1 and U2
  t = 32.407, df = 46, p-value < 2.2e-16
  alternative hypothesis: true difference in means is not equal to 0
  95 percent confidence interval:
   57.67003 65.30870
  sample estimates:
  mean of the differences 
                 61.48936 

#+end_src

*** 7.4.3 When there are more than two groups

    Use ANOVA if you can assume the data are sampled from an IDD population.

** Section 7.5 Nonparametric tests of group differences

*** 7.5.1 Comparing two groups 

    If the 2 groups are indpenednet, you can use the Wilcoxon rank sum test
    (Mann-Whitney U test) to assess whether the obs are sampled from the same
    probability distribution.

#+begin_src R
  > with(UScrime, by(Prob, So, median))
  So: 0
  [1] 0.038201
  ------------------------------------------------------------ 
  So: 1
  [1] 0.055552

  > wilcox.test(Prob ~ So, data=UScrime)

    Wilcoxon rank sum exact test

  data:  Prob by So
  W = 81, p-value = 8.488e-05
  alternative hypothesis: true location shift is not equal to 0
#+end_src

    Adding the ~paired=TRUE~ option provides a nonparametric alternative to the
    dependent t-test. It's appropriate in situations where the groups are paried
    and the assumption of normality is unwarranted.

#+begin_src R
  > sapply(UScrime[c("U1","U2")], median)
  U1 U2 
  92 34

  > with(UScrime, wilcox.test(U1, U2, paired=TRUE))
    Wilcoxon signed rank test with continuity correction

  data:  U1 and U2
  V = 1128, p-value = 2.464e-09
  alternative hypothesis: true location shift is not equal to 0

#+end_src

*** 7.5.2 Comparing more than two groups

    If you can’t meet the assumptions of ANOVA designs, you can use
    nonparametric methods to evaluate group differences. If the groups are
    independent, a Kruskal–Wallis test provides a useful approach. If the groups
    are dependent (for example, repeated measures or randomized block design),
    the Friedman test is more appropriate.


#+begin_src R
  states <- data.frame(state.region, state.x77)

  > kruskal.test(Illiteracy ~ state.region, data=states)

    Kruskal-Wallis rank sum test

  data:  Illiteracy by state.region
  Kruskal-Wallis chi-squared = 22.672, df = 3, p-value = 4.726e-05
#+end_src

#+begin_src R
  source("http://www.statmethods.net/RiA/wmc.txt")

  states <- data.frame(state.region, state.x77)
  > wmc(Illiteracy ~ state.region, data=states, method="holm")
  Descriptive Statistics

             West North Central Northeast    South
  n      13.00000      12.00000   9.00000 16.00000
  median  0.60000       0.70000   1.10000  1.75000
  mad     0.14826       0.14826   0.29652  0.59304

  Multiple Comparisons (Wilcoxon Rank Sum Tests)
  Probability Adjustment = holm

          Group.1       Group.2    W            p    
  1          West North Central 88.0 8.665618e-01    
  2          West     Northeast 46.5 8.665618e-01    
  3          West         South 39.0 1.788186e-02   *
  4 North Central     Northeast 20.5 5.359707e-02   .
  5 North Central         South  2.0 8.051509e-05 ***
  6     Northeast         South 18.0 1.187644e-02   *
  ---
  Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#+end_src

** Section 7.6 Visualizing group differences

   R provides a wide range of graphical methods for comparing groups, including
   box plots (simple, notched, and violin); overlapping kernel density plots;
   and graphical methods for visualizing outcomes in an ANOVA framework,
   discussed in chapter 9. Advanced methods for visualizing group differences,
   including grouping and faceting, are discussed in chapter 19.
